{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SignalP 5.0 Benchmark set (Eukarya Subset)\n",
    "\n",
    "Evaluate performance of custom models on the SignalP 5.0 Benchmark set, to see if it is comparable.  \n",
    "__Important:__ This is just an initial check for orders of magnitude. Models still need to pass proper evaluation either on a val set or crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_scripts.utils.signalp_dataset import PartitionThreeLineFastaDataset\n",
    "ds = PartitionThreeLineFastaDataset('../data/signalp_5_data/benchmark_set.fasta', kingdom_id=['EUKARYA'])\n",
    "dl = torch.utils.data.DataLoader(ds, collate_fn=ds.collate_fn, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To be solved\n",
    "- Why do benchmark set seqs have a partition number?\n",
    "\n",
    "#### AWDLSTM-CRF Eukarya performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.sp_tagging_awd_lstm import ProteinAWDLSTMSequenceTaggingCRF\n",
    "model = ProteinAWDLSTMSequenceTaggingCRF.from_pretrained('../model_checkpoints/sp_prediction_models/best_mlp_tagging_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a932affeb4744e0cbe2756b708007a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=373.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses, global_probs, probs, pos_preds, global_targets, targets = [], [], [] ,[], [], []\n",
    "model.eval()\n",
    "for i, b in tqdm(enumerate(dl), total=len(dl)):\n",
    "    target = b[1]\n",
    "    global_target = (target == 0).any(axis =1) *1\n",
    "    with torch.no_grad():\n",
    "        loss, global_prob, prob, pos_pred = model(b[0], targets= target, global_targets=global_target)\n",
    "    losses.append(loss)\n",
    "    global_probs.append(global_prob)\n",
    "    probs.append(prob)\n",
    "    pos_preds.append(pos_pred)\n",
    "    targets.append(b[1])\n",
    "    global_targets.append(global_target)\n",
    "\n",
    "global_targets = torch.cat(global_targets)\n",
    "global_probs = torch.cat(global_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC for SP detection : 0.902\n"
     ]
    }
   ],
   "source": [
    "#NOTE as long as this is binary (=eukarya model), argmax is ok. Otherwise not so sure.\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, precision_score\n",
    "mcc_detection = matthews_corrcoef(global_targets.numpy(), np.argmax(global_probs.numpy(), axis =1))\n",
    "print(f'MCC for SP detection : {mcc_detection:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_utils import tagged_seq_to_cs\n",
    "true_cs = tagged_seq_to_cs(torch.cat(targets).numpy())\n",
    "pred_cs = tagged_seq_to_cs(torch.cat(pos_preds).numpy())\n",
    "#replace nan with -1 to make metric functions work\n",
    "true_cs[np.isnan(true_cs)] = -1\n",
    "pred_cs[np.isnan(pred_cs)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC for CS tagging (no tolerance window) : 0.687\n",
      "Accuracy: 0.981\n"
     ]
    }
   ],
   "source": [
    "mcc_cs = matthews_corrcoef(true_cs[~np.isnan(true_cs)], pred_cs[~np.isnan(true_cs)])\n",
    "#precision = precision_score(true_cs[~np.isnan(true_cs)], pred_cs[~np.isnan(true_cs)])\n",
    "accuracy = accuracy_score(true_cs[~np.isnan(true_cs)], pred_cs[~np.isnan(true_cs)])\n",
    "print(f'MCC for CS tagging (no tolerance window) : {mcc_cs:.3f}')\n",
    "print(f'Accuracy: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "#generate .fasta format for SignalP web server\n",
    "with open('euk_benchmark.fasta', 'w') as f:\n",
    "    for x,y  in zip(ds.identifiers[5000:], ds.sequences[5000:]):\n",
    "        f.write(x)\n",
    "        f.write('\\n')\n",
    "        f.write(y)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SignalP webserver results on same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC for SP detection : 0.920\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('signalp_results_benchmark_set_euk.tsv', sep ='\\t')\n",
    "mcc_detection = matthews_corrcoef(global_targets.numpy(), df['Prediction'].astype('category').cat.codes)\n",
    "\n",
    "print(f'MCC for SP detection : {mcc_detection:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_pos = df['CS Position'].str.extract(r'([0-9]{1,2})-')\n",
    "cs_pos[cs_pos.isna()] = -1\n",
    "cs_pos = cs_pos.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC for CS tagging (no tolerance window) : 0.840\n",
      "Accuracy: 0.991\n"
     ]
    }
   ],
   "source": [
    "mcc_cs = matthews_corrcoef(true_cs[~np.isnan(true_cs)], cs_pos[~np.isnan(true_cs)])\n",
    "accuracy = accuracy_score(true_cs[~np.isnan(true_cs)], cs_pos[~np.isnan(true_cs)])\n",
    "print(f'MCC for CS tagging (no tolerance window) : {mcc_cs:.3f}')\n",
    "print(f'Accuracy: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- SignalP outperforms AWDLSTM-CRF.\n",
    "- SignalP seems to perform better than stated in the supplementary material.\n",
    "- Clarification needed for nested cross-validation? What is the final model trained on? If trained on all, this would explain the weakness of AWDLSTM-CRF a bit. Model has seen 40% less data than SignalP, so has a harder time predicting those homology groups.\n",
    "\n",
    "- __AWDLSTM-CRF performance still looks competitive. Together with the better performance seen on plasmodium, worthy of further pursuing.__\n",
    "\n",
    "______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Split (Famsa partition 0) ==20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PartitionThreeLineFastaDataset('../data/signalp_5_data/famsa_225_partitions/partition_0.0.fasta')\n",
    "dl = torch.utils.data.DataLoader(ds, collate_fn=ds.collate_fn, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e8b0f1973246838aa22471102bd610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=248.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses, global_probs, probs, pos_preds, global_targets, targets = [], [], [] ,[], [], []\n",
    "model.eval()\n",
    "for i, b in tqdm(enumerate(dl), total=len(dl)):\n",
    "    target = b[1]\n",
    "    global_target = (target == 0).any(axis =1) *1\n",
    "    with torch.no_grad():\n",
    "        loss, global_prob, prob, pos_pred = model(b[0], targets= target, global_targets=global_target)\n",
    "    losses.append(loss)\n",
    "    global_probs.append(global_prob)\n",
    "    probs.append(prob)\n",
    "    pos_preds.append(pos_pred)\n",
    "    targets.append(b[1])\n",
    "    global_targets.append(global_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9218481802331078"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_targets = torch.cat(global_targets)\n",
    "global_probs = torch.cat(global_probs)\n",
    "pos_preds = torch.cat(pos_preds)\n",
    "targets = torch.cat(targets)\n",
    "matthews_corrcoef(global_targets.numpy(), np.argmax(global_probs.numpy(), axis =1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9786515298497976"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SignalP performance on partition 0\n",
    "signalp_preds = pd.read_csv('partition_0_signalp.txt', sep ='\\t')['Prediction'].astype('category').cat.codes.values\n",
    "matthews_corrcoef(global_targets.numpy(), signalp_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
